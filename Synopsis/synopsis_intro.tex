\section*{General description of work} 


%\subsection*{Background}

The rapid advancements in Deep Learning (DL) have established a strong foundation for automating medical image segmentation tasks~\cite{lee2017deep}. Segmentation algorithms, particularly those based on Convolutional Neural Networks (CNNs), have achieved near human-level performance across a variety of clinical applications, including brain tumor, lung cancer, organ-at-risk, and liver tumor segmentation. These algorithms continue to evolve, offering increasingly accurate results.

%In our previous work, we have demonstrated the practical impact of carefully developed DL methods in real clinical workflows. For instance, we contributed to the radiotherapeutic delineation process at the Moscow Gamma-Knife Center by developing a model that provides accurate brain metastases segmentation contours~\cite{shirokikh2022systematic}. Additionally, our work on automatic COVID-19 identification and severity triage has been successfully integrated into the Moscow healthcare system, streamlining patient management~\cite{goncharov2021ct,covid-program}.

Despite this progress, the widespread deployment of CNN-based segmentation models in clinical practice remains significantly constrained. A central limitation is the lack of model robustness under domain shift -- a phenomenon where systematic differences in data distribution arise due to variation in scanner vendors, acquisition protocols, reconstruction algorithms, patient populations, or healthcare institutions. When a model trained on one data domain is evaluated on a different domain, even without any semantic changes, its performance often degrades dramatically. In medical imaging, this effect has been documented across multiple modalities, including Magnetic Resonance Imaging (MRI) and Computed Tomography (CT), and across various tasks such as brain tissue, tumor, and COVID-19 lesion segmentation~\cite{shirokikh2020first,zakazov2021anatomy,saparov2021zero,shimovolos2022adaptation}.

To address this issue, domain adaptation (DA) methods have been actively explored. DA focuses on transferring knowledge from a labeled source domain to an unlabeled or differently-distributed target domain. Although numerous DA techniques have been proposed specifically in medical imaging~\cite{gulrajani2020search,uda_survey_2020,zhuang2020comprehensive,peng2018visda,zhang2021empirical}, most methods are validated under narrow experimental settings that do not fully reflect the diversity and complexity of real clinical scenarios. Specifically, the medical imaging datasets used are often either private, too small for robust training and evaluation, or limited to a single domain shift source or synthetic task. Moreover, methods addressing severe and frequently encountered in practice domain shifts, such as varying reconstruction kernels in CT, are mostly ignored and underdeveloped.

Therefore, the field of medical image segmentation urgently requires domain adaptation techniques that are effective under realistic domain shifts, scalable to large 3D datasets, and rigorously evaluated in clinically representative conditions. This dissertation addresses these needs through the development of novel DA methods, introduction of robust evaluation benchmarks, and publication of heterogeneous datasets, with the overarching goal of enabling safe, accurate, and generalizable deployment of deep learning models in clinical medical imaging workflows.


\underline{\textbf{Relevance of the work.}}
The research presented in this dissertation addresses an impactful problem in the field of artificial intelligence and medical imaging: the lack of robustness and generalization of deep learning models under domain shift. Despite remarkable progress in developing CNNs for medical image segmentation, their deployment in real-world clinical environments remains limited due to the sharp degradation in performance when data characteristics change, such as those caused by differences in scanner hardware, acquisition protocols, or reconstruction algorithms. This issue is particularly acute in 3D medical imaging, where annotated data is scarce and domain variability is high.

This thesis focuses on the development and evaluation of domain adaptation methods for 3D segmentation models. The developed methods, including SpotTUnet, FBPAug, and F-Consistency, demonstrate strong potential for improving the robustness of medical segmentation models across diverse imaging protocols and clinical environments. The introduced M3DA and OOD detection benchmarks provide systematic tools for evaluating domain adaptation and reliability of segmentation algorithms in real-world scenarios. Furthermore, the published Burdenko Glioblastoma Progression dataset offers a clinically relevant testbed for developing and validating domain adaptation methods in radiotherapy planning. Altogether, the results of this dissertation contribute to advancing the safe deployment of deep learning in clinical practice and help bridge the gap between algorithmic development and medical application. This research contributes to the methodological foundations of deep learning in healthcare by enhancing the adaptability and reliability of medical image segmentation models.


\underline{\textbf{Goals and problems addressed.}} This research is devoted to the development of robust DL methods for 3D medical image segmentation under domain shift. The work focuses on both algorithmic contributions to supervised and unsupervised DA, and on establishing standardized benchmarks and datasets to support realistic evaluation of generalization in medical imaging. The results are demonstrated on clinically relevant segmentation tasks using MRI and CT data.
To achieve this goal, the following problems are addressed:

\begin{enumerate}
    \item Domain Shift Analysis in MRI and CT: Estimate the sensitivity of segmentation models to different sources of domain shift in MRI and CT images. Identify CNN layers most affected by domain shift and propose a strategies for automatic layer selection and interpretable domain adaptation.
    \item Development of DA Algorithms: Design a physics-informed augmentation method to simulate CT kernel-induced shift. Develop a data-driven unsupervised adaptation method based on enforcing feature map similarity between paired CT images. Implement and evaluate supervised and unsupervised adaptation pipelines in low-data and zero-shot settings.
    \item Benchmarking Robustness in 3D Medical Imaging at Scale: Construct a realistic and large-scale benchmark to systematically assess DA performance across varied domain shift scenarios in MRI and CT segmentation tasks. Collect and release a clinically realistic dataset -- a large-scale, annotated collection from multiple clinical centers and scanner vendors. Assess generalization of segmentation models under heterogeneous real-world conditions and evaluate state-of-the-art DA methods, reporting their limitations. Develop an OOD benchmark with several clinically relevant test cases and evaluate standard methods. % glioblastoma MRI collection
\end{enumerate}

\underline{\textbf{Scientific novelty.}}
The scientific novelty is built up from the following results:

\begin{enumerate}
	
	\item A novel gradient-based method, SpotTUnet, is proposed and implemented to automatically identify and fine-tune the neural network layers most susceptible to domain shifts in supervised DA settings, improving segmentation performance under limited data availability.
	
	\item A knowledge-driven augmentation technique, FBPAug, is developed for the first time to simulate the effect of CT reconstruction kernel variability, significantly improving segmentation consistency.
	
	\item A data-driven unsupervised domain adaptation method, F-Consistency, is developed for the first time to address CT reconstruction kernel variability by enforcing feature map similarity between paired images. The method achieves state-of-the-art performance under kernel-induced domain shifts and establishes a foundation for future self-supervised learning approaches using FBPAug-generated pairs and the F-Consistency criterion.
	
	\item A large-scale benchmark, M3DA, was introduced for evaluating unsupervised domain adaptation methods in 3D medical image segmentation, revealing critical limitations of existing approaches -- none of which close more than 61\% of the performance gap between source and target domains.
	
	\item A new publicly available dataset for primary glioblastoma segmentation in radiotherapy planning is collected and published. It allows for testing domain adaptation methods in the close to clinical scenarios.
	
	\item A benchmark for out-of-distribution detection in 3D medical imaging is constructed for the first time, containing multiple challenge scenarios and exposing critical limitations of existing OOD detection methods.
	
\end{enumerate}

\underline{\textbf{Theoretical and practical significance.}}
From a theoretical perspective, the dissertation contributes novel formulations and learning principles for domain adaptation in 3D medical image segmentation. The proposed SpotTUnet method introduces a gradient-based criterion for identifying domain-shift-sensitive layers in CNNs, offering new insights into the structural behavior of deep models under distributional shift. The FBPAug method is grounded in the mathematics of computed tomography, providing a parametrically controlled augmentation technique to simulate domain shifts caused by reconstruction kernels. F-Consistency formulates an unsupervised learning objective based on the similarity of internal representations, establishing a principled approach for leveraging paired but unlabeled data. These developments enrich the foundations of machine learning, domain adaptation in particular, and support further study into robustness and model generalization.

On the practical side, the proposed methods have been shown to significantly improve segmentation robustness under clinically relevant domain shifts, including those caused by acquisition parameters, reconstruction algorithms, and institutional variability. The developed M3DA benchmark provides a comprehensive framework for empirical evaluation of DA algorithms, while the published BGP dataset enables realistic testing in radiotherapy planning scenarios. Additionally, the OOD detection benchmark and the IHF method contribute to building reliable diagnostic pipelines capable of identifying OOD inputs in practice. %Collectively, the results of this research support safer and more generalizable deployment of deep learning models in real-world medical imaging workflows, bridging the gap between theoretical advancements and clinical applicability.

\underline{\textbf{Research methodology.}} The research employs machine learning and deep learning techniques to improve the generalization and robustness of CNNs in 3D medical image segmentation, focusing on both supervised and unsupervised learning paradigms. Methodologically, the work integrates tools from linear algebra, probability theory, mathematical statistics, and numerical optimization to develop and analyze domain adaptation algorithms.

Experimental evaluation relies on large-scale empirical studies using publicly available and newly introduced benchmarks and datasets. All methods are implemented in the Python programming language using established DL frameworks. Software components were designed for reproducibility and extensibility, supporting broader use in medical image analysis. Clinical relevance and task formulation were refined through collaboration with medical experts in radiology and radiation oncology.

\underline{\textbf{Propositions submitted for defense.}}

\begin{enumerate}
	\item A novel supervised domain adaptation method, SpotTUnet, was developed to automatically identify and fine-tune layers most affected by domain shift. The method improved segmentation performance in MRI across diverse clinical domains and provided interpretable insights into layer-wise shift susceptibility. Used as a visualization or guidance tool, SpotTUnet contributed to the development of the further proposed methods, such as F-Consistency and IHF.
	\item A knowledge-driven augmentation technique, FBPAug, was proposed to address domain shifts caused by different CT reconstruction kernels. The method significantly increased prediction consistency across paired reconstructions, improving Dice score from 0.46 to 0.76 in COVID-19 lung segmentation. Furthermore, FBPAug was used to develop most of the commercially used CT segmentation algorithms, significantly improving their robustness.
	\item A data-driven unsupervised adaptation method, F-Consistency, was introduced to leverage paired CT images reconstructed with different kernels. By enforcing feature map similarity, the method achieved state-of-the-art results in kernel-induced domain shift settings, further increasing Dice score to 0.80.
	\item The M3DA benchmark was constructed for the large-scale evaluation of unsupervised DA methods in 3D medical image segmentation. It comprises four publicly available datasets and eight clinically relevant domain shift setups, including shifts across modalities, acquisition protocols, and contrast settings.
	\item A new dataset, Burdenko’s Glioblastoma Progression (BGP), was collected and published to evaluate segmentation models in a realistic DA scenario. It includes multi-sequence MRI scans from 180 patients acquired across multiple clinical sites and scanner vendors, enabling testing under heterogeneous acquisition variability.
	\item A benchmark for OOD detection in 3D medical segmentation was proposed, containing several clinically relevant challenge cases. It revealed fundamental limitations of existing OOD methods and established practical evaluation criteria for real-world robustness assessment.
	\item An effective OOD detection method, Intensity Histogram Features (IHF), was developed. With the lowest computational cost, it achieved top-2 ranking in the Medical Out-of-Distribution Challenge (MOOD) 2022 and 2023, making it a strong baseline and analysis tool for domain shifts in 3D medical images.
\end{enumerate}


\underline{\textbf{Validity of the obtained results. Approbation.}} The statements and conclusions formulated in the dissertation have received qualified approbation at the following international and Russian scientific conferences:

\begin{enumerate}
	\item Domain Adaptation and Representation Transfer MICCAI 2020 Workshop. Lima, Peru, October 2020.
	\item Cross-Modality Domain Adaptation for Medical Image Segmentation (challenge-associated satellite event at MICCAI). Strasbourg, France, September 2021.
	\item Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI). Strasbourg, France, September 2021.
	\item Information Technologies and Systems (ITaS) conference. November 2021.
	\item Medical Out-of-Distribution Analysis Challenge (challenge-associated satellite event at MICCAI). Singapore, September 2022.
	\item Information Technologies and Systems (ITaS) conference. Istra, Russia, September 2023.
\end{enumerate}

The reliability of the results is ensured by comprehensive experimental evaluation across multiple datasets, diverse experimental settings, and multiple methods of statistical analysis, with all validation procedures in accordance with the leading work in the area. The reproducibility of findings was validated through systematic benchmarking of multiple deep learning algorithms and repeated experiments to ensure statistical significance of the results. All the proposed methods are compared with existing methods for domain adaptation or OOD detection using measurable metrics.

The credibility is also confirmed by two publications of research results in Q1 peer-reviewed scientific journals, two publications in Q2 peer-reviewed journals, and three peer-reviewed conference proceedings, including one in proceedings of the Rank A conference. All of these journals and proceedings are indexed in Scopus and Web of Science.


\underline{\textbf{Personal contribution of the author.}}
The content of the dissertation and the main statements submitted for defense reflect the author’s personal contribution to the published works, obtained personally by the author or with his direct participation. The author’s contribution includes the formulation of research objectives, literature analysis, design and execution of extensive computational experiments, and interpretation of the obtained results. The dissertation aims and objectives were formulated jointly by the author, the author’s scientific supervisor, Prof. Ivan V. Oseledets, and Dr. Mikhail G. Belyaev (IRA Labs Ltd).

Preparation of the seven publications (four in peer-reviewed journals and three in conference proceedings) was carried out together with co-authors, with the author’s contribution being decisive. In particular, the author proposed the core methodologies for domain adaptation and out-of-distribution detection, developed experimental pipelines, and analyzed experimental results. Additionally, the author contributed to the development of a software product registered by the state and to the creation of a publicly available medical imaging dataset.

\underline{\textbf{Dissertation structure.}}
The dissertation consists of~an abstract, introduction, 4 chapters, conclusions, lists of abbreviations, figures, tables, and 1 appendix. The full volume of the dissertation is 130 pages with 24 figures and 15 tables. The list of references contains 172 sources.


%\subsection*{Structure and volume of the dissertation} The dissertation consists of introduction, four chapters, conclusions, bibliography, list of symbols and abbreviations, list of tables, list of figures, list of 165 references. The full volume of the dissertation is 126 pages, including 26 figures and 18 tables.